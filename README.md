# Adversarial-Defenses-Talk

Final presentation for CMPS 290C: Advanced Topics in Machine Learning

Note:

In comparing the robustness of various optimizers to adversarial attacks, my intention was to compare an optimizer that makes use of regular additive updates with one using multiplicative updates. For the multiplicative update class, I chose to use exponentiated gradient plus/minus, and for the additive update, I chose the popular Adam optimizer. Unfortunately I labeled the results for Adam with "SGD", so please note that this is really a comparison between Adam and EG+-.
